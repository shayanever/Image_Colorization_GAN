{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7X3ILyXLrNz"
      },
      "source": [
        "N.N and deep learning\n",
        "Image recoloring\n",
        "Shahla Sadeghzadeh - Shayan Sharifi - Mohammad Vanaei"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBNPmbELrN2"
      },
      "source": [
        "1.first step is importing the needed library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wPzN6-1pLrN3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from fastai.data.external import untar_data, URLs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Q-ZMNZLrN4"
      },
      "source": [
        "Downloading images from COCO\n",
        "we considered 10000 images which we dedicated 8000 for training and 2\n",
        "000 for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWeJA3wwLrN5",
        "outputId": "567f4830-00e4-479d-c9d3-6fd587fd6aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# coco_path = untar_data(URLs.COCO_SAMPLE)\n",
        "# coco_path = str(coco_path) + \"/train_sample\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "652aedviLrN5",
        "outputId": "054ca92d-fba6-4217-a435-b2358d319ef8"
      },
      "outputs": [],
      "source": [
        "paths=glob.glob(\"/content/drive/MyDrive/deepdata/Deep/coco/*.jpg\")\n",
        "#paths = glob.glob(\"./data/coco_sample/train_sample/*.jpg\")\n",
        "np.random.seed(100)\n",
        "paths_subset = np.random.choice(paths, 1_0000, replace=False) # choosing 5000 images by random\n",
        "rand_idxs = np.random.permutation(1_0000)\n",
        "train_idxs = rand_idxs[:8000]\n",
        "val_idxs = rand_idxs[8000:]\n",
        "train_paths = paths_subset[train_idxs]\n",
        "val_paths = paths_subset[val_idxs]\n",
        "\n",
        "print(len(train_paths), len(val_paths))\n",
        "\n",
        "_, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "for ax, img_path in zip(axes.flatten(), train_paths):\n",
        "    ax.imshow(Image.open(img_path))\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjDXP-NLrN7"
      },
      "source": [
        "below code defines a dataset and data loaders for a colorization task using PyTorch. It loads images, converts them to the Lab color space, separates them into luminance (L) and color (ab) channels, and prepares them for training and validation. The data loaders enable efficient batch processing for training a colorization model.\n",
        "It converts the images to the Lab color space, which consists of three channels: L (luminance), a (green-red color component), and b (blue-yellow color component). The L channel represents the grayscale version of the image, while the a and b channels represent the color information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQYfQgVkLrN7",
        "outputId": "53d35d4f-cf82-430e-e1fc-bb851aad9075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n",
            "500 125\n"
          ]
        }
      ],
      "source": [
        "SIZE = 256\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE)),\n",
        "\n",
        "            ])\n",
        "        elif split == 'val':\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE))\n",
        "\n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\") #  RGB to Lab\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1.\n",
        "        ab = img_lab[[1, 2], ...] / 110.\n",
        "\n",
        "        return {'L': L, 'ab': ab}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs):\n",
        "    dataset = ColorizationDataset(**kwargs)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
        "val_dl = make_dataloaders(paths=val_paths, split='val')\n",
        "\n",
        "data = next(iter(train_dl))\n",
        "Ls, abs_ = data['L'], data['ab']\n",
        "print(Ls.shape, abs_.shape)\n",
        "print(len(train_dl), len(val_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPAo6P7QLrN8"
      },
      "source": [
        "UNet\n",
        " this code defines a U-Net architecture for image segmentation tasks. The U-Net architecture is composed of a series of downsampling (encoding) and upsampling (decoding) blocks, which allow it to capture fine-grained details and spatial information in images /n\n",
        "\n",
        "the defenition of parameters are below:/n\n",
        "\n",
        "in_channels: The number of input channels.\n",
        "out_channels: The number of output channels.\n",
        "submodule: A submodule to be used inside this block.\n",
        "input_channels: The number of input channels if not specified (defaults to out_channels).\n",
        "use_dropout: Whether to use dropout layers.\n",
        "is_innermost: Indicates if this is the innermost block.\n",
        "is_outermost: Indicates if this is the outermost block.\n",
        "/n\n",
        "Inside the UNetBlock class:\n",
        "\n",
        "The constructor sets up the block's layers based on the provided parameters.\n",
        "It includes convolutional layers, activation functions (ReLU or LeakyReLU), and batch normalization.\n",
        "The block structure varies depending on whether it's innermost, outermost, or a middle block.\n",
        "The forward method defines the forward pass through this block./n\n",
        "\n",
        "Define the UNet class:\n",
        "\n",
        "This class represents the entire U-Net architecture.\n",
        "It takes parameters for the number of input channels, number of output channels, the number of downscaling steps, and the number of filters to use.\n",
        "Inside the constructor:\n",
        "It initializes the innermost block with one downscaling step.\n",
        "Repeatedly, it adds middle blocks (with optional dropout) according to the specified number of downscaling steps.\n",
        "Finally, it sets up the outermost block.\n",
        "\n",
        "inside the UNet class:\n",
        "\n",
        "The forward method defines the forward pass through the entire U-Net architecture. It passes the input through all the blocks and returns the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKe6SYz_LrN9",
        "outputId": "c55b16f0-bcb8-4b61-dbc8-c4184f5e04a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (model): UnetBlock(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): UnetBlock(\n",
              "        (model): Sequential(\n",
              "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (3): UnetBlock(\n",
              "            (model): Sequential(\n",
              "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (3): UnetBlock(\n",
              "                (model): Sequential(\n",
              "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (3): UnetBlock(\n",
              "                    (model): Sequential(\n",
              "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                      (3): UnetBlock(\n",
              "                        (model): Sequential(\n",
              "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                          (3): UnetBlock(\n",
              "                            (model): Sequential(\n",
              "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                              (3): UnetBlock(\n",
              "                                (model): Sequential(\n",
              "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                                  (2): ReLU(inplace=True)\n",
              "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                                  (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                                )\n",
              "                              )\n",
              "                              (4): ReLU(inplace=True)\n",
              "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                              (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                              (7): Dropout(p=0.5, inplace=False)\n",
              "                            )\n",
              "                          )\n",
              "                          (4): ReLU(inplace=True)\n",
              "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                          (7): Dropout(p=0.5, inplace=False)\n",
              "                        )\n",
              "                      )\n",
              "                      (4): ReLU(inplace=True)\n",
              "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                      (7): Dropout(p=0.5, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (4): ReLU(inplace=True)\n",
              "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )\n",
              "              (4): ReLU(inplace=True)\n",
              "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (4): ReLU(inplace=True)\n",
              "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): ConvTranspose2d(128, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (4): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "        if input_c is None: input_c = nf\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=False)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(ni)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = nn.BatchNorm2d(nf)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            if dropout: up += [nn.Dropout(0.5)]\n",
        "            model = down + [submodule] + up\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "        for _ in range(n_down - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
        "        out_filters = num_filters * 8\n",
        "        for _ in range(3):\n",
        "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
        "            out_filters //= 2\n",
        "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Unet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXpWg_VDLrN-"
      },
      "source": [
        "Discriminator\n",
        "This PatchGAN discriminator is designed to take an image as input and produce a spatial grid of real/fake predictions at different locations in the image. It's commonly used in conditional GANs and image-to-image translation tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Czf5n4-3LrN-"
      },
      "outputs": [],
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
        "                          for i in range(n_down)] \n",
        "                                                  \n",
        "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] \n",
        "                                                                                             \n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): \n",
        "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          \n",
        "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
        "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_llRgsLFLrN-",
        "outputId": "d910d3a1-3de9-41ed-9e25-486ad3199cbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 1, 30, 30])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminator = PatchDiscriminator(3)\n",
        "dummy_input = torch.randn(16, 3, 256, 256) \n",
        "out = discriminator(dummy_input)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viSSzyUWLrN_"
      },
      "source": [
        "Gan loss\n",
        " this custom GAN loss class allows us to easily compute GAN losses for both 'vanilla' GAN and 'lsgan' scenarios by specifying the desired GAN mode during initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LiqeyS3-LrN_"
      },
      "outputs": [],
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNPRe8OjLrOA"
      },
      "source": [
        "Model Initialization\n",
        "We are going to initialize the weights of our model with a mean of 0.0 and standard deviation of 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RDizauRMLrOA"
      },
      "outputs": [],
      "source": [
        "def init_weights(net, init='norm', gain=0.02):\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "            if init == 'norm':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif 'BatchNorm2d' in classname:\n",
        "            nn.init.normal_(m.weight.data, 1., gain)\n",
        "            nn.init.constant_(m.bias.data, 0.)\n",
        "\n",
        "    net.apply(init_func)\n",
        "    print(f\"model initialized with {init} initialization\")\n",
        "    return net\n",
        "\n",
        "def init_model(model, device):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tAta5xFLrOA",
        "outputId": "3566f1f4-1d48-41e2-8acc-38af74a296ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model initialized with norm initialization\n"
          ]
        }
      ],
      "source": [
        "model = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkqmxkJmLrOB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IdbUnNGGLrOB"
      },
      "outputs": [],
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
        "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = lambda_L1\n",
        "\n",
        "        if net_G is None:\n",
        "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
        "        else:\n",
        "            self.net_G = net_G.to(self.device)\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    def set_requires_grad(self, model, requires_grad=True):\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "\n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)\n",
        "        self.ab = data['ab'].to(self.device)\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "\n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "        real_preds = self.net_D(real_image)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self):\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.set_requires_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        self.net_G.train()\n",
        "        self.set_requires_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7ItLG7LrOC"
      },
      "source": [
        "Utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j2khijvtLrOC"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def create_loss_meters():\n",
        "    loss_D_fake = AverageMeter()\n",
        "    loss_D_real = AverageMeter()\n",
        "    loss_D = AverageMeter()\n",
        "    loss_G_GAN = AverageMeter()\n",
        "    loss_G_L1 = AverageMeter()\n",
        "    loss_G = AverageMeter()\n",
        "\n",
        "    return {'loss_D_fake': loss_D_fake,\n",
        "            'loss_D_real': loss_D_real,\n",
        "            'loss_D': loss_D,\n",
        "            'loss_G_GAN': loss_G_GAN,\n",
        "            'loss_G_L1': loss_G_L1,\n",
        "            'loss_G': loss_G}\n",
        "\n",
        "def update_losses(model, loss_meter_dict, count):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        loss = getattr(model, loss_name)\n",
        "        loss_meter.update(loss.item(), count=count)\n",
        "\n",
        "def lab_to_rgb(L, ab):\n",
        "    \"\"\"\n",
        "    Takes a batch of images\n",
        "    \"\"\"\n",
        "\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(model, data, save=True):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    model.net_G.train()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "\n",
        "def log_results(loss_meter_dict):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpJBNDgQLrOD"
      },
      "source": [
        "Trainig function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "94ee51f8bd404923a2c25e009ecddd19",
            "de0ffd6ac1724dabacf878d223605346",
            "fef3f49b3bc94d44a12ec9d50fffa24e",
            "6dd9626d6cbf42ffa9b25651570f1307",
            "ac169e87e4db45e7bb0724fd678a21d6",
            "2958b7bbbca74401b94c0eff9431556a",
            "d26dd6d2482743e496ea31c10dd6de99",
            "cde1080319db4fb48170d82b0d1cdf64",
            "e915976df4394e12ab0063412cf79f75",
            "1b9a504f68584017a2400c3151d599db"
          ]
        },
        "id": "S3xG1Rq9LrOD",
        "outputId": "85b6e0c7-6871-4068-f45b-6a0702204c03"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dl, epochs, display_every=200):\n",
        "    data = next(iter(val_dl)) \n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters() \n",
        "        i = 0                                  \n",
        "        for data in tqdm(train_dl):\n",
        "            model.setup_input(data)\n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) \n",
        "            i += 1\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict) \n",
        "                visualize(model, data, save=False) \n",
        "\n",
        "model = MainModel()\n",
        "train_model(model, train_dl, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New solution (resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KEDha3zJLrOE"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.learner import create_body\n",
        "#from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "from torchvision.models import resnet18\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lLRi23OyLrOE"
      },
      "outputs": [],
      "source": [
        "def build_res_unet(n_input=1, n_output=2, size=256):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    modelrn = models.resnet18(pretrained=True)\n",
        "    #body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
        "    body = create_body(modelrn,n_in=n_input, pretrained=True,  cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MBw_K_3LrOE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "EmIZtPV5LrOE",
        "outputId": "5a077d77-0e16-4605-d568-a9fd475af7ba"
      },
      "outputs": [],
      "source": [
        "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
        "    for e in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for data in tqdm(train_dl):\n",
        "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
        "            preds = net_G(L)\n",
        "            loss = criterion(preds, ab)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "\n",
        "        print(f\"Epoch {e + 1}/{epochs}\")\n",
        "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n",
        "\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "opt = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "criterion = nn.L1Loss()\n",
        "pretrain_generator(net_G, train_dl, opt, criterion, 10)\n",
        "torch.save(net_G.state_dict(), \"res18-unet.pt\")\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
        "model = MainModel(net_G=net_G)\n",
        "train_model(model, train_dl, 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a-NgthejEmwm"
      },
      "outputs": [],
      "source": [
        "def train_model_res(model, train_dl, epochs, display_every=200):\n",
        "    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to\n",
        "        i = 0                                  # log the losses of the complete network\n",
        "        for data in tqdm(train_dl):\n",
        "            model.setup_input(data)\n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
        "            i += 1\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict) # function to print out the losses\n",
        "                visualize(model, data, save=False) # function displaying the model's outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uyuCKwfAEVTd",
        "outputId": "126068a7-f632-4be9-dfc5-63a30f52059f"
      },
      "outputs": [],
      "source": [
        "model = MainModel(net_G=net_G)\n",
        "train_model_res(model, train_dl, 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
